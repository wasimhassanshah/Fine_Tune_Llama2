{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ],
      "metadata": {
        "id": "KHpiNNzgHO9p"
      },
      "id": "KHpiNNzgHO9p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft trl bitsandbytes datasets transformers torch"
      ],
      "metadata": {
        "id": "eNf5_KpUHO1K"
      },
      "id": "eNf5_KpUHO1K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eef1e26-f1c9-49fe-a35e-1ff53f3e6a11",
      "metadata": {
        "id": "8eef1e26-f1c9-49fe-a35e-1ff53f3e6a11",
        "outputId": "f9dc0b10-7db2-4611-ce94-1b9bbecffcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.22.post7. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 512 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ac7a45-c012-4190-afb7-bab09b5657d3",
      "metadata": {
        "id": "56ac7a45-c012-4190-afb7-bab09b5657d3",
        "outputId": "157c1ad6-26fb-47ba-c016-87c85930fc68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],   # This setup injects LoRA adapters into both attention layers ((q_proj, k_proj, v_proj, o_proj), and feedforward layers ((gate_proj, up_proj, down_proj) ), making the model more adaptable with minimal parameter updates.\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a176474-3621-4478-9f04-c7e2490e932b",
      "metadata": {
        "id": "1a176474-3621-4478-9f04-c7e2490e932b"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "from datasets import load_dataset\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    texts = []\n",
        "    for question, cypher, schema in zip(examples['question'], examples['cypher'], examples['schema']):\n",
        "        convo = [\n",
        "            {\"role\": \"system\", \"content\": \"Given an input question, convert it to a Cypher query. No pre-amble.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"Based on the Neo4j graph schema below, write a Cypher query that would answer the user's question:\n",
        "{schema}\n",
        "\n",
        "Question: {question}\n",
        "Cypher query:\"\"\"},\n",
        "            {\"role\": \"assistant\", \"content\": f\"{cypher}\"}\n",
        "        ]\n",
        "        text = tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False)\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "hf_token = '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'\n",
        "dataset = load_dataset(\"abhi7991/text2cypher_gpt3.5\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9245465b-5185-49c7-80fb-5f300930a238",
      "metadata": {
        "id": "9245465b-5185-49c7-80fb-5f300930a238",
        "outputId": "ed8e70fd-85dc-46ee-b70f-322adca70d88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nGiven an input question, convert it to a Cypher query. No pre-amble.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nBased on the Neo4j graph schema below, write a Cypher query that would answer the user's question:\\nNode properties:\\nProduct {unit_of_measure_per_pack: STRING, line_item_quantity: STRING, pack_price: STRING, embedding: LIST, molecule_test_type: STRING, shipment_number: STRING, pid: INTEGER, item_description: STRING, project_code: STRING, price_quote: STRING}\\nCountry {name: STRING}\\nVendor {name: STRING}\\nBrand {name: STRING}\\nProduct_Group {name: STRING}\\nSub_Class {name: STRING}\\nOffice {name: STRING}\\nRelationship properties:\\nWEIGHT {weight: FLOAT}\\nThe relationships:\\n(:Product)-[:WEIGHT]->(:Country)\\n(:Product)-[:BRAND]->(:Brand)\\n(:Product)-[:GROUP]->(:Product_Group)\\n(:Product)-[:SUB_CLASS]->(:Sub_Class)\\n(:Vendor)-[:VENDOR]->(:Product)\\n(:Office)-[:MANAGED_BY]->(:Product)\\n\\nQuestion: Which vendors supply products to offices that manage more than 3 different types of product groups?\\nCypher query:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nMATCH (v:Vendor)-[:VENDOR]->(p:Product)-[:GROUP]->(pg:Product_Group)\\nMATCH (p)-[:MANAGED_BY]->(o:Office)\\nWITH v, o, count(DISTINCT pg) AS numProductGroups\\nWHERE numProductGroups > 3\\nRETURN DISTINCT v.name AS Vendor, o.name AS Office, numProductGroups as NumberOfProductGroups<|eot_id|>\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f780c4-f569-4839-b14f-f16899b5f13e",
      "metadata": {
        "id": "e4f780c4-f569-4839-b14f-f16899b5f13e"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "def get_device_map() -> str:\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "device = get_device_map()\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        num_train_epochs=2,\n",
        "        warmup_steps = 5,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4952cb1f-b697-489f-b901-80b6ca3af398",
      "metadata": {
        "id": "4952cb1f-b697-489f-b901-80b6ca3af398",
        "outputId": "05011238-42f2-4b18-c824-8217f9013070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "5.605 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae82455-ac42-4a61-add5-55e9cd395eba",
      "metadata": {
        "id": "2ae82455-ac42-4a61-add5-55e9cd395eba",
        "outputId": "741e4fec-adf2-4910-9a14-efd0efbd65c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 212 | Num Epochs = 2\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 52\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [52/52 06:13, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.325200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.344000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.240800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.070300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.814700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.531300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.280800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.039000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.834400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.641400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.527400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.456700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.350900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.330300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.248300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.220700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.207100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.218800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.197500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.228200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.202100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.174200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.188800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.183100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.180200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.172200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.152900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.139900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.158300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.180400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.131500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.157300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.134500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.147800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.164000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.138900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.151200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.140000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c95ecdd-2f71-4a13-bbd9-cf5e5d6fdb7a",
      "metadata": {
        "id": "4c95ecdd-2f71-4a13-bbd9-cf5e5d6fdb7a",
        "outputId": "7425ca6e-fab4-4fb8-e81e-fd512b4f0976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "381.3907 seconds used for training.\n",
            "6.36 minutes used for training.\n",
            "Peak reserved memory = 7.609 GB.\n",
            "Peak reserved memory for training = 2.004 GB.\n",
            "Peak reserved memory % of max memory = 51.593 %.\n",
            "Peak reserved memory for training % of max memory = 13.588 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a659cdb-c8b7-4208-a2ec-bc3ff45fe507",
      "metadata": {
        "id": "2a659cdb-c8b7-4208-a2ec-bc3ff45fe507",
        "outputId": "7edab392-fb2d-4163-fd6f-b90a4880e8b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nGiven an input question, convert it to a Cypher query. No pre-amble.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nBased on the Neo4j graph schema below, write a Cypher query that would answer the user's question:\\nNode properties:\\nProduct {unit_of_measure_per_pack: STRING, line_item_quantity: STRING, pack_price: STRING, embedding: LIST, molecule_test_type: STRING, shipment_number: STRING, pid: INTEGER, item_description: STRING, project_code: STRING, price_quote: STRING}\\nCountry {name: STRING}\\nVendor {name: STRING}\\nBrand {name: STRING}\\nProduct_Group {name: STRING}\\nSub_Class {name: STRING}\\nOffice {name: STRING}\\nRelationship properties:\\nWEIGHT {weight: FLOAT}\\nThe relationships:\\n(:Product)-[:WEIGHT]->(:Country)\\n(:Product)-[:BRAND]->(:Brand)\\n(:Product)-[:GROUP]->(:Product_Group)\\n(:Product)-[:SUB_CLASS]->(:Sub_Class)\\n(:Vendor)-[:VENDOR]->(:Product)\\n(:Office)-[:MANAGED_BY]->(:Product)\\n\\nQuestion: What are the top 5 products managed by the Haiti Field Office?\\nCypher query:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nMATCH (p:Product)-[:MANAGED_BY]->(:Office {name: 'Haiti Field Office'})\\nRETURN p\\nORDER BY p.pid\\nLIMIT 5<|eot_id|>\"]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n",
        "    map_eos_token = True, # Maps <|im_end|> to </s> instead\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Given an input question, convert it to a Cypher query. No pre-amble.\"},\n",
        "      {\"role\": \"user\", \"content\": f\"\"\"Based on the Neo4j graph schema below, write a Cypher query that would answer the user's question:\n",
        "{dataset[0]['schema']}\n",
        "\n",
        "Question: {dataset[0]['question']}\n",
        "Cypher query:\"\"\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e80d6d-b8b5-46bd-adea-1938ee0a9854",
      "metadata": {
        "id": "65e80d6d-b8b5-46bd-adea-1938ee0a9854",
        "outputId": "46a3bf1f-6e4f-41df-a6f7-cee9c8f34d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install seaborn\n",
        "stats = trainer.state.log_history[:-1]\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract data\n",
        "steps = [stat['step'] for stat in stats if 'step' in stat]\n",
        "epochs = [stat['epoch'] for stat in stats if 'epoch' in stat]\n",
        "loss = [stat['loss'] for stat in stats if 'loss' in stat]\n",
        "learning_rate = [stat['learning_rate'] for stat in stats if 'learning_rate' in stat]\n",
        "grad_norm = [stat['grad_norm'] for stat in stats if 'grad_norm' in stat]\n",
        "\n",
        "# Plot loss over steps\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=steps, y=loss, label='Loss')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Steps')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"Loss-llama.png\")\n",
        "plt.show()\n",
        "\n",
        "# Plot learning rate over steps\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=steps, y=learning_rate, label='Learning Rate', color='orange')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate over Steps')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"learning_rate-llama.png\")\n",
        "plt.show()\n",
        "\n",
        "# Plot gradient norm over steps\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=steps, y=grad_norm, label='Gradient Norm', color='green')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Gradient Norm')\n",
        "plt.title('Gradient Norm over Steps')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"gradient-llama.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b90103-288a-43b7-995f-bfd76ba5be84",
      "metadata": {
        "id": "30b90103-288a-43b7-995f-bfd76ba5be84",
        "outputId": "35b796ec-0c14-4e8a-8915-d6b1cf610680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     Metric         Value\n",
            "0             train_runtime  3.813907e+02\n",
            "1  train_samples_per_second  1.112000e+00\n",
            "2    train_steps_per_second  1.360000e-01\n",
            "3                total_flos  5.783859e+15\n",
            "4                train_loss  4.647224e-01\n",
            "5                     epoch  1.962264e+00\n",
            "6                      step  5.200000e+01\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(trainer.state.log_history[-1],index=[0]).T.reset_index()\n",
        "df.columns = ['Metric','Value']\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008ad57f-0e1c-4f1f-aad0-e0af563115ed",
      "metadata": {
        "id": "008ad57f-0e1c-4f1f-aad0-e0af563115ed",
        "outputId": "bf787bdd-0e2e-4c48-c81a-8fa40fa61b8b",
        "colab": {
          "referenced_widgets": [
            "e2e5b5bc0737409cac30c12b44eb6f8b",
            "6080abae6b9343a6b8371d7123a23480"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "make: Entering directory '/teamspace/studios/this_studio/llama.cpp'\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE \n",
            "I NVCCFLAGS: -std=c++11 -O3 -g \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "I CXX:       c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "\n",
            "rm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
            "rm -rvf src/*.o\n",
            "rm -rvf tests/*.o\n",
            "rm -rvf examples/*.o\n",
            "rm -rvf common/*.o\n",
            "rm -rvf *.a\n",
            "rm -rvf *.dll\n",
            "rm -rvf *.so\n",
            "rm -rvf *.dot\n",
            "rm -rvf ggml/*.a\n",
            "rm -rvf ggml/*.dll\n",
            "rm -rvf ggml/*.so\n",
            "rm -vrf ggml/src/*.o\n",
            "rm -rvf common/build-info.cpp\n",
            "rm -vrf ggml/src/ggml-metal-embed.metal\n",
            "rm -vrf ggml/src/ggml-cuda/*.o\n",
            "rm -vrf ggml/src/ggml-cuda/template-instances/*.o\n",
            "rm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o\n",
            "rm -rvf tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
            "rm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\n",
            "rm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize benchmark-matmult parallel export-lora lookahead lookup passkey gritlm\n",
            "find examples pocs -type f -name \"*.o\" -delete\n",
            "make: Leaving directory '/teamspace/studios/this_studio/llama.cpp'\n",
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 17.52 out of 30.89 RAM for saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [00:01<00:01, 10.51it/s]We will save to Disk and not RAM now.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:54<00:00,  1.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at model into f16 GGUF format.\n",
            "The output location will be ./model/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: model\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 8192\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128255\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if message['role'] == 'user' %}{{ '<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "' + message['content'] | trim + '<|eot_id|>' }}{% elif message['role'] == 'assistant' %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' + message['content'] | trim + '<|eot_id|>' }}{% else %}{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "' + message['content'] | trim + '<|eot_id|>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:model/unsloth.F16.gguf: n_tensors = 291, total_size = 16.1G\n",
            "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.1G/16.1G [02:59<00:00, 89.6Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to model/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: ./model/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3525 (0a4ce786)\n",
            "main: built with cc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0 for x86_64-linux-gnu\n",
            "main: quantizing './model/unsloth.F16.gguf' to './model/unsloth.Q4_K_M.gguf' as Q4_K_M using 16 threads\n",
            "llama_model_loader: loaded meta data with 28 key-value pairs and 291 tensors from ./model/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3 8b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ä  Ä \", \"Ä  Ä Ä Ä \", \"Ä Ä  Ä Ä \", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128255\n",
            "llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
            "llama_model_loader: - kv  27:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                    token_embd.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
            "[   2/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[   4/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   5/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   6/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   7/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   8/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   9/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  10/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  11/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  13/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  14/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  15/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  16/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  17/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  18/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  19/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  20/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  22/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  23/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  24/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  25/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  26/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  27/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  28/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  29/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  31/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  32/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  33/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  34/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  35/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  36/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  37/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  38/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  40/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  41/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  42/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  43/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  44/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  45/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  46/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  47/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  49/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  50/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  51/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  52/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  53/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  54/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  55/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  56/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  58/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  59/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  60/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  61/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  62/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  63/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  64/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  65/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  67/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  68/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  69/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  70/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  71/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  72/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  73/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  74/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  76/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  77/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  78/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  79/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  80/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  81/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  82/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  83/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  85/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  86/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  87/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  88/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  89/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  90/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  91/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  92/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  94/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  95/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  96/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  97/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  98/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  99/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 100/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 101/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 103/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 104/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 105/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 106/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 107/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 108/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 109/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 110/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 112/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 113/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 114/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 115/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 116/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 117/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 118/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 119/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 121/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 122/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 123/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 124/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 125/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 126/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 127/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 128/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 130/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 131/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 132/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 133/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 134/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 135/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 136/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 137/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 139/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 140/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 141/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 142/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 143/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 144/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 145/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 146/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 148/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 149/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 150/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 151/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 152/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 153/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 154/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 155/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 157/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 158/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 159/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 160/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 161/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 162/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 163/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 164/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 166/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 167/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 168/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 169/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 170/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 171/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 172/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 173/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 174/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 175/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 176/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 177/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 178/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 179/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 180/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 182/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 184/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 185/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 186/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 187/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 188/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 189/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 191/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 193/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 194/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 195/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 196/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 197/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 198/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 199/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 200/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 202/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 203/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 204/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 205/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 206/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 207/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 208/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 209/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 211/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 212/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 213/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 214/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 215/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 216/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 217/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 218/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 220/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 221/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 222/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 223/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 224/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 225/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 226/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 227/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 229/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 230/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 231/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 232/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 233/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 234/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 235/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 236/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 238/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 239/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 240/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 241/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 242/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 243/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 244/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 245/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 247/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 248/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 249/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 250/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 251/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 252/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 253/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 254/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 256/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 257/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 258/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 259/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 260/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 261/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 262/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 263/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 265/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 266/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 267/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 268/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 269/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 270/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 271/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 272/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 274/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 275/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 276/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 277/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 278/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 279/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 280/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 281/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 282/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 285/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 287/ 291]                        output.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
            "[ 288/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 289/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "llama_model_quantize_internal: model size  = 15317.02 MB\n",
            "llama_model_quantize_internal: quant size  =  4685.30 MB\n",
            "\n",
            "main: quantize time = 281249.35 ms\n",
            "main:    total time = 281249.35 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### We removed it in GGUF's chat template for you.\n",
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Conversion completed! Output location: ./model/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Saved Ollama Modelfile to model/Modelfile\n",
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 16.16 out of 30.89 RAM for saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:20<00:00,  1.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at abhi7991/promptfinetuning-llama3 into f16 GGUF format.\n",
            "The output location will be ./abhi7991/promptfinetuning-llama3/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: promptfinetuning-llama3\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 8192\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128255\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if message['role'] == 'user' %}{{ '<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "' + message['content'] | trim + '<|eot_id|>' }}{% elif message['role'] == 'assistant' %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' + message['content'] | trim + '<|eot_id|>' }}{% else %}{{ '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "' + message['content'] | trim + '<|eot_id|>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:abhi7991/promptfinetuning-llama3/unsloth.F16.gguf: n_tensors = 291, total_size = 16.1G\n",
            "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.1G/16.1G [03:08<00:00, 85.0Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to abhi7991/promptfinetuning-llama3/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: ./abhi7991/promptfinetuning-llama3/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3525 (0a4ce786)\n",
            "main: built with cc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0 for x86_64-linux-gnu\n",
            "main: quantizing './abhi7991/promptfinetuning-llama3/unsloth.F16.gguf' to './abhi7991/promptfinetuning-llama3/unsloth.Q4_K_M.gguf' as Q4_K_M using 16 threads\n",
            "llama_model_loader: loaded meta data with 28 key-value pairs and 291 tensors from ./abhi7991/promptfinetuning-llama3/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3 8b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ä  Ä \", \"Ä  Ä Ä Ä \", \"Ä Ä  Ä Ä \", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128255\n",
            "llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
            "llama_model_loader: - kv  27:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                    token_embd.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
            "[   2/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[   4/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   5/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   6/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   7/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   8/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   9/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  10/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  11/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  13/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  14/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  15/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  16/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  17/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  18/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  19/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  20/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  22/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  23/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  24/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  25/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  26/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  27/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  28/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  29/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  31/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  32/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  33/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  34/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  35/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  36/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  37/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  38/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  40/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  41/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  42/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  43/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  44/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  45/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  46/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  47/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  49/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  50/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  51/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  52/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  53/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  54/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  55/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  56/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  58/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  59/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  60/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  61/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  62/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  63/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  64/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  65/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  67/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  68/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  69/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  70/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  71/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  72/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  73/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  74/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  76/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  77/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  78/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  79/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  80/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  81/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  82/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  83/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  85/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  86/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  87/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  88/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  89/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  90/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  91/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  92/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  94/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  95/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  96/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  97/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  98/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  99/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 100/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 101/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 103/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 104/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 105/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 106/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 107/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 108/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 109/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 110/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 112/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 113/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 114/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 115/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 116/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 117/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 118/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 119/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 121/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 122/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 123/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 124/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 125/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 126/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 127/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 128/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 130/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 131/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 132/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 133/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 134/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 135/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 136/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 137/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 139/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 140/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 141/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 142/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 143/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 144/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 145/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 146/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 148/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 149/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 150/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 151/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 152/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 153/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 154/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 155/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 157/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 158/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 159/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 160/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 161/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 162/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 163/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 164/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 166/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 167/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 168/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 169/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 170/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 171/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 172/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 173/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 174/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 175/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 176/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 177/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 178/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 179/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 180/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 182/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 184/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 185/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 186/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 187/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 188/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 189/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 191/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 193/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 194/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 195/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 196/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 197/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 198/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 199/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 200/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 202/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 203/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 204/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 205/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 206/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 207/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 208/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 209/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 211/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 212/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 213/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 214/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 215/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 216/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 217/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 218/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 220/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 221/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 222/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 223/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 224/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 225/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 226/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 227/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 229/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 230/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 231/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 232/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 233/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 234/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 235/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 236/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 238/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 239/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 240/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 241/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 242/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 243/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 244/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 245/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 247/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 248/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 249/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 250/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 251/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 252/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 253/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 254/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 256/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 257/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 258/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 259/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 260/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 261/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 262/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 263/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 265/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 266/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 267/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 268/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 269/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 270/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 271/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 272/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 274/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 275/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 276/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 277/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 278/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 279/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 280/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 281/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 282/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 285/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 287/ 291]                        output.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
            "[ 288/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 289/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "llama_model_quantize_internal: model size  = 15317.02 MB\n",
            "llama_model_quantize_internal: quant size  =  4685.30 MB\n",
            "\n",
            "main: quantize time = 272009.78 ms\n",
            "main:    total time = 272009.78 ms\n",
            "Unsloth: Conversion completed! Output location: ./abhi7991/promptfinetuning-llama3/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Saved Ollama Modelfile to abhi7991/promptfinetuning-llama3/Modelfile\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2e5b5bc0737409cac30c12b44eb6f8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unsloth.F16.gguf:   0%|          | 0.00/16.1G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved GGUF to https://huggingface.co/abhi7991/promptfinetuning-llama3\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6080abae6b9343a6b8371d7123a23480",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved GGUF to https://huggingface.co/abhi7991/promptfinetuning-llama3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Unsloth: ##### The current model auto adds a BOS token.\n",
            "Unsloth: ##### We removed it in GGUF's chat template for you.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Ollama Modelfile to https://huggingface.co/abhi7991/promptfinetuning-llama3\n"
          ]
        }
      ],
      "source": [
        "# Save to q4_k_m GGUF\n",
        "if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if True: model.push_to_hub_gguf(\"abhi7991/promptfinetuning-llama3\", tokenizer, quantization_method = \"q4_k_m\", token = hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4445bd15-2e4d-46e5-909e-40e350fece5a",
      "metadata": {
        "id": "4445bd15-2e4d-46e5-909e-40e350fece5a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}